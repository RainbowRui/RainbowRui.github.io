<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="viewport" content="width=800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
    a {
    color: #2171b5;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #d94801;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    /* font-family: 'Roboto', sans-serif; */
    font-size: 15px;
    font-weight: 400
    }
    .hp-photo{ width:240px; height:240px; border-radius:240px; -webkit-border-radius:240px; -moz-border-radius:240px; }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    /* font-family: 'Roboto', sans-serif; */
    font-size: 15px;
    font-weight: 600
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    /* font-family: 'Roboto', sans-serif; */
    font-size: 24px;
    font-weight: 600
    }
    papertitle {
    /* font-family: 'Lato', Verdana, Helvetica, sans-serif; */
    font-family: 'Roboto', sans-serif;
    color: 	#084594;
    font-size: 16px;
    font-weight: 600
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    /* font-family: 'Roboto', sans-serif; */
    font-size: 32px;
    font-weight: 600
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
    </style>

    <title>Hongrui Cai | USTC</title>
    <!--<link rel="stylesheet" type="text/css" href="/imgs/css" >-->
    <link rel="icon" type="image/jpg" href="./imgs/ustc_icon.png">
</head>

<body>
<table width="840" border="0" align="center" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<td>


    <!--SECTION 1 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="61.8%" valign="middle">
                <p align="center"><name>Hongrui Cai (蔡泓锐)</name></p>
                  <p align="justify">I am a Ph.D. candidate in the Graphics&Geometric Computing Laboratory (GCL)
                    at University of Science and Technology of China (USTC), supervised by Prof. <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>.
                    Before that, I obtained my B.S. degree from South China University of Technology (SCUT) in 2019.

					<br><br><strong>Email:</strong> hrcai AT mail.ustc.edu.cn
	            </br>
                </p><p align="center">
                    <a href="https://scholar.google.com/citations?user=fqoe18wAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                    <a href="https://github.com/RainbowRui">Github</a> &nbsp;/&nbsp;
	                <a href="https://www.linkedin.com/in/hongrui-cai-5a5a12191/">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="./CurriculumVitae_HongruiCai.pdf">CV</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="./imgs/photo.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="./imgs/photo.jpg" class="hoverZoomLink"></a>
              </td></tr>
			  <!--<td align="right"> <img class="hp-photo" src="./imgs/photo.jpg" style="width: 165;"></td> -->
            </tbody>
          </table>


    <!--SECTION 2 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>Research Interests</heading>
		  <p align="justify">My research interests include some sub-fields of <b>Computer Vision</b> and <b>Computer Graphics</b>:</p>
<ul>
<li><p><b>3D Reconstruction</b> and Structure-from-motion</p>
</li>
<li><p>Point Cloud Learning and Surface Registration</p>
</li>
<li><p><b>Animatable Avatar</b></p>
</li>
</ul>
</p></br></tr>
       </tbody>
    </table>


    <!--SECTION 3 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td><heading>News</heading>
            <p align="justify"><b>[2022.09]</b> One paper accepted by <a href="https://nips.cc/">NeurIPS 2022</a> (1 Poster).</p>
            <p align="justify">[2022.06] One paper accepted by <a href="https://2022.acmmm.org/">ACM MM 2022</a> (1 Poster).</p>
	        <p align="justify">[2022.03] One paper accepted by <a href="http://cvpr2022.thecvf.com/">CVPR 2022</a> (1 Poster).</p>
          </td>
       </tr></tbody>
    </table>

    <!--SECTION 4 -->
    <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading>Preprints</heading>
          </td>
          </tr>
		  </tbody>
    </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>

            <td width="20%"><img src="./imgs/NDR.png" alt="arxiv2022" style="width:220px;"></td>
            <td width="80%" valign="center">
                 <p>
                 <papertitle>Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera</papertitle>
                 <br><strong>Hongrui Cai</strong>, <a href="https://github.com/WanquanF">Wanquan Feng</a>,
                 <a href="https://scholar.google.com/citations?hl=en&user=5G-2EFcAAAAJ">Xuetao Feng</a>, Yan Wang,
                 <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>.<br>
                 <em>arXiv</em>, 2022.
                 <br>
		         <a href="https://ustc3dv.github.io/ndr/">project page</a> /
                 <a href="https://arxiv.org/pdf/2206.15258.pdf">paper</a>
                 <p align="justify" style="font-size:13px">We propose Neural-DynamicReconstruction (NDR), a template-free method to recover high-fidelity geometry and motions of a dynamic scene from a monocular RGB-D camera.  To represent and constrain the non-rigid deformations, we propose a novel neural invertible deforming network such that the cycle consistency between arbitrary two frames is automatically satisfied.</p>
                <p></p>
            </td>

        </tr> -->
			
    <!--SECTION 5 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading>Publications</heading>
          </td>
          </tr>
		  </tbody>
    </table>


	<!-- <h3>&nbsp;&nbsp;&nbsp;&nbsp;Conference Papers</h3> -->
    <!--SECTION 6 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>

    <td width="20%"><img src="./imgs/NDR.png" alt="NeurIPS2022" style="width:240px;"></td>
            <td width="80%" valign="center">
                 <p>
                 <papertitle>Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera</papertitle>
                 <br><strong>Hongrui Cai</strong>, <a href="https://github.com/WanquanF">Wanquan Feng</a>,
                 <a href="https://scholar.google.com/citations?hl=en&user=5G-2EFcAAAAJ">Xuetao Feng</a>, Yan Wang,
                 <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>.<br>
                 <br>
                 <em>NeurIPS</em>, 2022<br>
		         <a href="https://ustc3dv.github.io/ndr/">project page</a> /
                 <a href="https://arxiv.org/pdf/2206.15258.pdf">paper</a> /
                 <a href="https://openreview.net/forum?id=8RKJj1YDBJT">OpenReview</a> /
                 <a href="./data/NDR_poster.pdf">poster</a> /
                 <a href="https://github.com/USTC3DV/NDR-code">code</a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=USTC3DV&repo=NDR-code&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                 <p align="justify" style="font-size:13px">We propose Neural-DynamicReconstruction (NDR), a template-free method to recover high-fidelity geometry and motions of a dynamic scene from a monocular RGB-D camera.  To represent and constrain the non-rigid deformations, we propose a novel neural invertible deforming network such that the cycle consistency between arbitrary two frames is automatically satisfied.</p>
                <p></p>
            </td>
    </tr>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>

    <td width="20%"><img src="./imgs/CariPainter.png" alt="ACMMM2022" style="width:240px;"></td>
            <td width="80%" valign="center">
                 <p>
                 <papertitle>CariPainter: Sketch Guided Interactive Caricature Generation</papertitle>
                 <br>Xin Huang, Dong Liang, <strong>Hongrui Cai</strong>,
                 <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>, Jinyuan Jia.<br>
                 <br>
                 <em>ACM MM</em>, 2022<br>
                 <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548085">paper & video</a>
                 <p align="justify" style="font-size:13px">We propose CariPainter, the first interactive caricature generating and editing method, by utilizing the semantic segmentation maps as an intermediary domain.</p>
                <p></p>
            </td>
    </tr>

   <td width="20%"><img src="./imgs/NeuralPoints.png" alt="CVPR2022" style="width:240px;"></td>
            <td width="80%" valign="center">
                 <p>
                 <papertitle>Neural Points: Point Cloud Representation with Neural Fields for Arbitrary Upsampling</papertitle>
                 <br><a href="https://github.com/WanquanF">Wanquan Feng</a>, Jin Li,
	         <strong>Hongrui Cai</strong>, <a href="https://www.guet.edu.cn/people/info/1003/2398.htm">Xiaonan Luo</a>,
                 <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>.<br>
                 <br>
                 <em>CVPR</em>, 2022<br>
		         <a href="https://wanquanf.github.io/NeuralPoints">project page</a> /
                 <a href="https://arxiv.org/pdf/2112.04148.pdf">paper</a> /
		         <a href="https://www.zhihu.com/question/519162597/answer/2393206762">zhihu</a> /
		         <a href="https://github.com/WanquanF/NeuralPoints">code</a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=WanquanF&repo=NeuralPoints&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                 <p align="justify" style="font-size:13px">In this paper, we propose Neural Points, a novel point cloud representation. Different from traditional point cloud representation, each point in Neural Points represents a local continuous geometric shape via neural fields. Therefore, Neural Points can express more complex geometry shapes.</p>
                <p></p>
            </td>
	</tr>

   <td width="20%"><img src="./imgs/RMA-Net.jpg" alt="CVPR2021" style="width:240px;"></td>
            <td width="80%" valign="center">
                 <p>
                 <papertitle>Recurrent Multi-view Alignment Network for Unsupervised Surface Registration</papertitle>
                 <br><a href="https://github.com/WanquanF">Wanquan Feng</a>, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>, 
                 <strong>Hongrui Cai</strong>, <a href="https://haofeixu.github.io/">Haofei Xu</a>, 
                 <a href="https://sites.google.com/site/junhuihoushomepage/">Junhui Hou</a>, <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>.<br>
                 <br>
                 <em>CVPR</em>, 2021<br>
                 <a href="https://wanquanf.github.io/RMA-Net.html">project page</a> /
                 <a href="https://arxiv.org/pdf/2011.12104.pdf">paper</a> /
                 <a href="https://zhuanlan.zhihu.com/p/380831519">zhihu</a> /
                 <a href="https://github.com/WanquanF/RMA-Net">code</a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=WanquanF&repo=RMA-Net&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                 <p align="justify" style="font-size:13px">For non-rigid registration, we propose RMA-Net to deform the input surface shape stage by stage. RMA-Net is trained in an unsupervised manner via our proposed multi-view 2D projection loss.</p>
                <p></p>
            </td>
        </tr>

        </tbody>
    </table>


	<!-- <h3>&nbsp;&nbsp;&nbsp;&nbsp;Journal Papers</h3> -->
	<!--SECTION 7 -->
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>

	<td width="20%"><img src="./imgs/CaricatureFace.jpg" alt="GMOD2021" style="width:240px;"></td>
            <td width="80%" valign="center">
                 <p>
                 <papertitle>Landmark Detection and 3D Face Reconstruction for Caricature using a Nonlinear Parametric Model</papertitle>
                 <br><strong>Hongrui Cai</strong>, <a href="https://yudongguo.github.io/">Yudong Guo</a>, 
                 Zhuang Peng, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>.<br>
                 <br>
                 <em>Graphical Models (GMOD)</em>, 2021<br>
                 <a href="https://arxiv.org/pdf/2004.09190.pdf">paper</a> /
                 <a href="https://drive.google.com/file/d/1oUc9XnjBtTJ5PBrIOWTxQrCGoW_LBnCD/view?usp=sharing">slides</a> /
                 <a href="https://zhuanlan.zhihu.com/p/389870247">zhihu</a> /
		         <a href="https://github.com/Juyong/CaricatureFace">code</a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=Juyong&repo=CaricatureFace&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
                 <p align="justify" style="font-size:13px">To the best of our knowledge, this is the first work for automatic landmark detection and 3D face reconstruction for general caricatures.</p>
                <p></p>
            </td>
	</tr>
		
		<td width="20%"><img src="./imgs/PerspectiveCorrection.jpg" alt="CVM2021" style="width:240px;"></td>
            <td width="80%" valign="center">
                 <p>
                 <papertitle>Real-time Face View Correction for Front-facing Cameras</papertitle>
                 <br><a href="https://yudongguo.github.io/">Yudong Guo</a>, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>, 
                 Yihua Chen, <strong>Hongrui Cai</strong>, <a href="http://staff.ustc.edu.cn/~zhuang/">Zhangjin Huang</a>, 
                 <a href="http://www.bdeng.me/">Bailin Deng</a>.<br>
                 <br>
                 <em>Computational Visual Media (CVM)</em>, 2021<br>
                 <a href="https://link.springer.com/content/pdf/10.1007/s41095-021-0215-y.pdf">paper</a> /
		         <a href="data/FaceViewCorrection.mp4">video</a>
				
                 <p align="justify" style="font-size:13px">We take the video stream from a single RGB camera as input, and generate a video stream that emulates the view from a virtual camera at a designated location.</p>
                <p></p>
            </td>
        </tr>
	
        </tbody>
    </table>
			
    <!--SECTION 8 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading>Technical Projects</heading>
          </td>
          </tr>
		  </tbody>
    </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>

	<td width="20%"><img src="./imgs/LD-FER.png" alt="project" style="width:240px;"></td>
            <td width="80%" valign="center">
                 <papertitle>Landmark driven Facial Expression Recognition</papertitle>
                 <br><strong>Hongrui Cai</strong>.<br>
                 <br>
                 2020
                 <br>
                 <a href="https://github.com/RainbowRui/Landmark-Driven-Facial-Expression-Recognition">code</a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=RainbowRui&repo=Landmark-Driven-Facial-Expression-Recognition&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
                 <p align="justify" style="font-size:13px">Design a landmark-driven Facial Expression Recognition (FER) method without employing any pre-trained model from other tasks.</p>
                <p></p>
            </td>		
        </tr>
			
        </tbody>
    </table>


    <!--SECTION 9 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody><tr>
            <td><heading>Professional Activities</heading>
             <p align="justify"> Journal Reviewers of IEEE Transactions on Multimedia <strong>(TMM)</strong>, Computers & Graphics <strong>(C&G)</strong>.</p>
            </td>
            </tr></tbody>
    </table>


    <!--SECTION 10 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody><tr>
            <td><heading>Academic Talks</heading>
             <p align="justify">[2021.04] Invited talk about <a href="https://drive.google.com/file/d/1oUc9XnjBtTJ5PBrIOWTxQrCGoW_LBnCD/view?usp=sharing">Caricature Face</a> at <a href="http://iccvm.org/2021/home.htm">CVM 2021</a>.</p>
            </td>
            </tr></tbody>
    </table>

    <!--SECTION 11 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody><tr>
            <td><heading>Selected Honors</heading>
             <p align="justify"> <strong>First-class Academic Scholarships for Postgraduates</strong>, by USTC, 2019 - 2022.</p>
             <p align="justify"> <strong>Excellent Undergraduate Thesis Award</strong>, by SCUT, 2019.</p>
             <p align="justify"> <strong>Excellent Undergraduate Student</strong>, by SCUT, 2019.</p>
            </td>
            </tr></tbody>
    </table>

    <!--SECTION 12 -->
    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=a8ddb5&w=500&t=tt&d=OXnFLPaDhY6mE_z76oEOuPh3N8PzQ7N3YNPrjF7lemU&co=43a2ca&cmo=fdae6b&cmn=e6550d'></script>

    <!--SECTION 13 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody><tr>
            <td><br>
               <!--<p align="right"><font size="3">Erd&ouml;s = ? </font><br> -->
		       <p align="right"><font size="2"> Last update: 2022.10</font></p>
            </td>
         </tr>
         </tbody>
     </table>


</td>
</tr>
</tbody>
</table>
</body>
</html>
